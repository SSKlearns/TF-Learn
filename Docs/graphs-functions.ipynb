{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.function` allows to switch from eager execution to graph execution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eager execution means TensorFlow operations are executed in Python, and results are returned to Python unlike in `Graph Execution` where tensor computations are executed as `tf.Graph`. It contains set of `tf.Operation` and `tf.Tensor` objects."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They're useful in environments that do not have Python interpreter, like mobile applications. They are easily optimized, and let TensorFlow run faster and also in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 14:58:57.943432: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-04 14:58:58.070382: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-04 14:58:58.094501: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-04 14:58:58.559497: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-04 14:58:58.559543: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-04 14:58:58.559547: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import timeit\n",
    "from datetime import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `tf.Function` can be called directly as a function or a decorator. It takes a python function as an input and returns a function, which makes TensorFlow graph from python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 14:59:00.333005: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-04-04 14:59:00.333058: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: ssk-Dell-G15-5511\n",
      "2023-04-04 14:59:00.333062: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: ssk-Dell-G15-5511\n",
      "2023-04-04 14:59:00.333180: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 525.85.12\n",
      "2023-04-04 14:59:00.333195: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 525.85.12\n",
      "2023-04-04 14:59:00.333198: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 525.85.12\n",
      "2023-04-04 14:59:00.334088: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def function(x, y, b):\n",
    "    x = tf.matmul(x, y)\n",
    "    x = x + b\n",
    "    return x\n",
    "\n",
    "graph_function = tf.function(function)\n",
    "\n",
    "x1 = tf.constant([[1.0, 2.0]])\n",
    "y1 = tf.constant([[2.0], [3.0]])\n",
    "b1 = tf.constant(4.0)\n",
    "\n",
    "orig_value = function(x1, y1, b1).numpy()\n",
    "tf_value = graph_function(x1, y1, b1).numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Another way to create or call a tf.Function is by using it as a decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inner_function(x, y, b):\n",
    "    x = tf.matmul(x, y)\n",
    "    x = x + b\n",
    "    return x\n",
    "\n",
    "# Using the decorator to call\n",
    "@tf.function\n",
    "def outer_function (x):\n",
    "    y = tf.constant([[1.0], [4.0]])\n",
    "    b = tf.constant(5.0)\n",
    "    return inner_function(x, y, b)\n",
    "\n",
    "# This will now create a graph that includes the inner function as well as the outer function\n",
    "outer_function(tf.constant([[1.0, 3.0]])).numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow code will have TF operations as well as Python logic, so we need to undergo the extra step to add it to the graph. `tf.function` uses a library `tf.autograph` to convert Python code to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Python function:  1\n",
      "Function converted to Tensorflow:  1\n"
     ]
    }
   ],
   "source": [
    "def simple_relu(x):\n",
    "    if tf.greater(x, 0):\n",
    "        return x\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "print(\"Original Python function: \", simple_relu(tf.constant(1)).numpy())\n",
    "\n",
    "# This will create a graph that includes the if statement\n",
    "tf_simple_relu = tf.function(simple_relu)\n",
    "\n",
    "print(\"Function converted to Tensorflow: \", tf_simple_relu(tf.constant(1)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__simple_relu(x):\n",
      "    with ag__.FunctionScope('simple_relu', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "\n",
      "        def get_state():\n",
      "            return (do_return, retval_)\n",
      "\n",
      "        def set_state(vars_):\n",
      "            nonlocal retval_, do_return\n",
      "            (do_return, retval_) = vars_\n",
      "\n",
      "        def if_body():\n",
      "            nonlocal retval_, do_return\n",
      "            try:\n",
      "                do_return = True\n",
      "                retval_ = ag__.ld(x)\n",
      "            except:\n",
      "                do_return = False\n",
      "                raise\n",
      "\n",
      "        def else_body():\n",
      "            nonlocal retval_, do_return\n",
      "            try:\n",
      "                do_return = True\n",
      "                retval_ = 0\n",
      "            except:\n",
      "                do_return = False\n",
      "                raise\n",
      "        ag__.if_stmt(ag__.converted_call(ag__.ld(tf).greater, (ag__.ld(x), 0), None, fscope), if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is the graph code\n",
    "print(tf.autograph.to_code(simple_relu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node {\n",
      "  name: \"x\"\n",
      "  op: \"Placeholder\"\n",
      "  attr {\n",
      "    key: \"_user_specified_name\"\n",
      "    value {\n",
      "      s: \"x\"\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shape\"\n",
      "    value {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Greater/y\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "        }\n",
      "        int_val: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Greater\"\n",
      "  op: \"Greater\"\n",
      "  input: \"x\"\n",
      "  input: \"Greater/y\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"cond\"\n",
      "  op: \"StatelessIf\"\n",
      "  input: \"Greater\"\n",
      "  input: \"x\"\n",
      "  attr {\n",
      "    key: \"Tcond\"\n",
      "    value {\n",
      "      type: DT_BOOL\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tin\"\n",
      "    value {\n",
      "      list {\n",
      "        type: DT_INT32\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tout\"\n",
      "    value {\n",
      "      list {\n",
      "        type: DT_BOOL\n",
      "        type: DT_INT32\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_lower_using_switch_merge\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_read_only_resource_inputs\"\n",
      "    value {\n",
      "      list {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"else_branch\"\n",
      "    value {\n",
      "      func {\n",
      "        name: \"cond_false_88\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"output_shapes\"\n",
      "    value {\n",
      "      list {\n",
      "        shape {\n",
      "        }\n",
      "        shape {\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"then_branch\"\n",
      "    value {\n",
      "      func {\n",
      "        name: \"cond_true_87\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"cond/Identity\"\n",
      "  op: \"Identity\"\n",
      "  input: \"cond\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_BOOL\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"cond/Identity_1\"\n",
      "  op: \"Identity\"\n",
      "  input: \"cond:1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Identity\"\n",
      "  op: \"Identity\"\n",
      "  input: \"cond/Identity_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "library {\n",
      "  function {\n",
      "    signature {\n",
      "      name: \"cond_true_87\"\n",
      "      input_arg {\n",
      "        name: \"cond_identity_1_x\"\n",
      "        type: DT_INT32\n",
      "      }\n",
      "      output_arg {\n",
      "        name: \"cond_identity\"\n",
      "        type: DT_BOOL\n",
      "      }\n",
      "      output_arg {\n",
      "        name: \"cond_identity_1\"\n",
      "        type: DT_INT32\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_BOOL\n",
      "            tensor_shape {\n",
      "            }\n",
      "            bool_val: true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Identity\"\n",
      "      op: \"Identity\"\n",
      "      input: \"cond/Const:output:0\"\n",
      "      attr {\n",
      "        key: \"T\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Identity_1\"\n",
      "      op: \"Identity\"\n",
      "      input: \"cond_identity_1_x\"\n",
      "      attr {\n",
      "        key: \"T\"\n",
      "        value {\n",
      "          type: DT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    ret {\n",
      "      key: \"cond_identity\"\n",
      "      value: \"cond/Identity:output:0\"\n",
      "    }\n",
      "    ret {\n",
      "      key: \"cond_identity_1\"\n",
      "      value: \"cond/Identity_1:output:0\"\n",
      "    }\n",
      "    attr {\n",
      "      key: \"_construction_context\"\n",
      "      value {\n",
      "        s: \"kEagerRuntime\"\n",
      "      }\n",
      "    }\n",
      "    arg_attr {\n",
      "      key: 0\n",
      "      value {\n",
      "        attr {\n",
      "          key: \"_output_shapes\"\n",
      "          value {\n",
      "            list {\n",
      "              shape {\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  function {\n",
      "    signature {\n",
      "      name: \"cond_false_88\"\n",
      "      input_arg {\n",
      "        name: \"cond_placeholder\"\n",
      "        type: DT_INT32\n",
      "      }\n",
      "      output_arg {\n",
      "        name: \"cond_identity\"\n",
      "        type: DT_BOOL\n",
      "      }\n",
      "      output_arg {\n",
      "        name: \"cond_identity_1\"\n",
      "        type: DT_INT32\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_BOOL\n",
      "            tensor_shape {\n",
      "            }\n",
      "            bool_val: true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const_1\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_BOOL\n",
      "            tensor_shape {\n",
      "            }\n",
      "            bool_val: true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const_2\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_INT32\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_INT32\n",
      "            tensor_shape {\n",
      "            }\n",
      "            int_val: 0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const_3\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_BOOL\n",
      "            tensor_shape {\n",
      "            }\n",
      "            bool_val: true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Identity\"\n",
      "      op: \"Identity\"\n",
      "      input: \"cond/Const_3:output:0\"\n",
      "      attr {\n",
      "        key: \"T\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const_4\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_INT32\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_INT32\n",
      "            tensor_shape {\n",
      "            }\n",
      "            int_val: 0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Identity_1\"\n",
      "      op: \"Identity\"\n",
      "      input: \"cond/Const_4:output:0\"\n",
      "      attr {\n",
      "        key: \"T\"\n",
      "        value {\n",
      "          type: DT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    ret {\n",
      "      key: \"cond_identity\"\n",
      "      value: \"cond/Identity:output:0\"\n",
      "    }\n",
      "    ret {\n",
      "      key: \"cond_identity_1\"\n",
      "      value: \"cond/Identity_1:output:0\"\n",
      "    }\n",
      "    attr {\n",
      "      key: \"_construction_context\"\n",
      "      value {\n",
      "        s: \"kEagerRuntime\"\n",
      "      }\n",
      "    }\n",
      "    arg_attr {\n",
      "      key: 0\n",
      "      value {\n",
      "        attr {\n",
      "          key: \"_output_shapes\"\n",
      "          value {\n",
      "            list {\n",
      "              shape {\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "versions {\n",
      "  producer: 1205\n",
      "  min_consumer: 12\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is the graph\n",
    "print(tf_simple_relu.get_concrete_function(tf.constant(1)).graph.as_graph_def())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time a new graph with a set of arguments that involve a new dtype, they can't be handled by existing graphs, so the function creates a new tf.Graph specialized to those arguments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type specification of a graph's inputs are known as the its `input signature` or just `signature`. The function store the tf.Graph corresponding to that signature in a `ConcreteFunction` wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This call creates graph with input signature of float:  tf.Tensor(3.3, shape=(), dtype=float32)\n",
      "This call creates graph with input signature of array:  tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function tf_relu at 0x7f764411cee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "This call creates graph with input signature of float array:  tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def tf_relu(x):\n",
    "    return tf.maximum(0., x)\n",
    "\n",
    "''' Since graphs are created only when funtions are called,\n",
    "    the below calls will create new graphs for each call '''\n",
    "\n",
    "print(\"This call creates graph with input signature of float: \", tf_relu(tf.constant(3.3)))\n",
    "print(\"This call creates graph with input signature of array: \", tf_relu([1, -1]))\n",
    "print(\"This call creates graph with input signature of float array: \", tf_relu(tf.constant([1.0, -1.0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This signature has been used before:  tf.Tensor(2.2, shape=(), dtype=float32)\n",
      "This signature has been used before:  tf.Tensor([0. 2.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# The following calls will not create new graphs as the signatures have been called before\n",
    "print(\"This signature has been used before: \", tf_relu(tf.constant(2.2)))\n",
    "print(\"This signature has been used before: \", tf_relu(tf.constant([-2., 2.])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_relu(x)\n",
      "  Args:\n",
      "    x: float32 Tensor, shape=()\n",
      "  Returns:\n",
      "    float32 Tensor, shape=()\n",
      "\n",
      "tf_relu(x=[1, -1])\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(2,)\n",
      "\n",
      "tf_relu(x)\n",
      "  Args:\n",
      "    x: float32 Tensor, shape=(2,)\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(2,)\n"
     ]
    }
   ],
   "source": [
    "print(tf_relu.pretty_printed_concrete_signatures())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can turn off function's ability to create and run graphs. We can make it execute eagerly using `tf.config.run_functions_eagerly(True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "tf_relu(tf.constant(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(False)\n",
    "tf_relu(tf.constant(1.0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph vs Eager execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_MSE(y_true, y_pred):\n",
    "    print(\"Calculating MSE\")\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([7 4 0 1 0], shape=(5,), dtype=int32)\n",
      "tf.Tensor([7 0 2 0 2], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "y_true = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
    "y_pred = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
    "\n",
    "print(y_true)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MSE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=5>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Graph execution\n",
    "tf.config.run_functions_eagerly(False)\n",
    "\n",
    "get_MSE(y_true, y_pred)\n",
    "get_MSE(y_true, y_pred)\n",
    "get_MSE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MSE\n",
      "Calculating MSE\n",
      "Calculating MSE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=5>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eager execution\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "get_MSE(y_true, y_pred)\n",
    "get_MSE(y_true, y_pred)\n",
    "get_MSE(y_true, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the print statement executes only once in graph execution. This is because the function runs original code to create graph by tracing which only captures TensorFlow operations into a graph. So the Python code is `run` only once and not captured in the graph so it is never executed again."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can overcome this using the TensorFlow version of the functions like `tf.print` for the above case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_MSE(y_true, y_pred):\n",
    "    tf.print(\"Calculating MSE\")\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MSE\n",
      "Calculating MSE\n",
      "Calculating MSE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=5>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Graph execution\n",
    "tf.config.run_functions_eagerly(False)\n",
    "\n",
    "get_MSE(y_true, y_pred)\n",
    "get_MSE(y_true, y_pred)\n",
    "get_MSE(y_true, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed difference between graph and eager execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.uniform(shape=[10, 10], minval=-1, maxval=2, dtype=tf.dtypes.int32)\n",
    "\n",
    "def power(x, y):\n",
    "  result = tf.eye(10, dtype=tf.dtypes.int32)\n",
    "  for _ in range(y):\n",
    "    result = tf.matmul(x, result)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager execution: 2.2354137409984105 seconds\n",
      "Graph execution: 0.3370804419992055 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Eager execution:\", timeit.timeit(lambda: power(x, 100), number=1000), \"seconds\")\n",
    "\n",
    "power_graph = tf.function(power)\n",
    "\n",
    "print(\"Graph execution:\", timeit.timeit(lambda: power_graph(x, 100), number=1000), \"seconds\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-strict execution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph execution only executes the operations necessary to produce observable results like the return function.\n",
    "Side effects:-\n",
    "    1. Input/Output operations\n",
    "    2. Debugging operations like assert in `tf.debugging`\n",
    "    3. Mutations of tf.Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs speed up code majorly, but takes a lot of time to trace a function, that is, create the graph. However this tradeoff is worth as you only trace once."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `print` statements within functions to know whenever your graph traces. They execute only once, which the first time when the function traces, so we will come to know when a function is being traced."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
