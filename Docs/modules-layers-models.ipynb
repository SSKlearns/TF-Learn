{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 10:04:15.241697: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-08 10:04:15.330526: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-08 10:04:15.357674: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-08 10:04:15.779161: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-08 10:04:15.779202: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-08 10:04:15.779207: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most models are made of layers. The high level implementations of layers and models such as `Keras` and `Sonnet` are built on foundational class `tf.Module`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 10:04:17.600008: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-04-08 10:04:17.600033: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: ssk-Dell-G15-5511\n",
      "2023-04-08 10:04:17.600037: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: ssk-Dell-G15-5511\n",
      "2023-04-08 10:04:17.600146: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 525.85.12\n",
      "2023-04-08 10:04:17.600159: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 525.85.12\n",
      "2023-04-08 10:04:17.600162: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 525.85.12\n",
      "2023-04-08 10:04:17.600742: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=24.0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimpleModule(tf.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.a_variable = tf.Variable(4.0, name=\"trainable_variable\")\n",
    "        self.non_trainable_variable = tf.Variable(4.0, trainable=False, name=\"untrainable_variable\")\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.a_variable * x + self.non_trainable_variable\n",
    "    \n",
    "simple_module = SimpleModule(name=\"simple\")\n",
    "\n",
    "simple_module(tf.constant(5.0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`__call__` acts like a Python callable and enables us to invoke our models with whatever functions we wish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable variables:  (<tf.Variable 'trainable_variable:0' shape=() dtype=float32, numpy=4.0>,)\n",
      "Non-trainable variables:  (<tf.Variable 'untrainable_variable:0' shape=() dtype=float32, numpy=4.0>,)\n",
      "All variables:  (<tf.Variable 'trainable_variable:0' shape=() dtype=float32, numpy=4.0>, <tf.Variable 'untrainable_variable:0' shape=() dtype=float32, numpy=4.0>)\n"
     ]
    }
   ],
   "source": [
    "# Printing all trainable variables\n",
    "print(\"Trainable variables: \", simple_module.trainable_variables)\n",
    "\n",
    "# Printing all non-trainable variables\n",
    "print(\"Non-trainable variables: \", simple_module.non_trainable_variables)\n",
    "\n",
    "# Printing all variables\n",
    "print(\"All variables: \", simple_module.variables)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two layer linear layer model with modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Dense layer\n",
    "class Dense(tf.Module):\n",
    "    def __init__(self, input_features, output_features, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.w = tf.Variable(tf.random.normal([input_features, output_features]), name=\"w\")\n",
    "        self.b = tf.Variable(tf.zeros([output_features]), name=\"b\")\n",
    "\n",
    "    def __call__(self, x):\n",
    "        y = tf.matmul(x, self.w) + self.b\n",
    "        return tf.nn.relu(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results:  tf.Tensor([[5.123894  0.8491444]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Complete model with 2 layers\n",
    "class Sequential(tf.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.Dense1 = Dense(3, 3)\n",
    "        self.Dense2 = Dense(3, 2)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.Dense1(x)\n",
    "        return self.Dense2(x)\n",
    "    \n",
    "# Create an instance of the model\n",
    "my_model = Sequential(name=\"the_model\")\n",
    "print(\"Model results: \", my_model(tf.constant([[2.0, 2.0, 2.0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submodules:  (<__main__.Dense object at 0x7f14040f2020>, <__main__.Dense object at 0x7f149dd7eb00>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Submodules: \", my_model.submodules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables (<tf.Variable 'b:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>, <tf.Variable 'w:0' shape=(3, 3) dtype=float32, numpy=\n",
      "array([[-0.03326015, -1.2288424 ,  1.083338  ],\n",
      "       [ 1.2849374 ,  1.3659351 ,  0.3940538 ],\n",
      "       [-0.8969859 , -0.07141123,  0.38183758]], dtype=float32)>, <tf.Variable 'b:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>, <tf.Variable 'w:0' shape=(3, 2) dtype=float32, numpy=\n",
      "array([[ 0.46655902, -0.06010991],\n",
      "       [-0.5344113 ,  2.2106724 ],\n",
      "       [ 1.307834  ,  0.1617296 ]], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Variables\", my_model.variables)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the same model with flexible input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class flexibleDense(tf.Module):\n",
    "    def __init__(self, output_features, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.is_built = False\n",
    "        self.output_features = output_features\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if not self.is_built:\n",
    "            self.w = tf.Variable(tf.random.normal([x.shape[-1], self.output_features]), name='Weights')\n",
    "            self.b = tf.Variable(tf.zeros([self.output_features]), name='Bias')\n",
    "            self.is_built = True\n",
    "        \n",
    "        y = tf.matmul(x, self.w) + self.b\n",
    "        return tf.nn.relu(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results:  tf.Tensor([[2.6006083 0.7657103]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Complete model with 2 layers\n",
    "class Sequential(tf.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.Dense1 = flexibleDense(3)\n",
    "        self.Dense2 = flexibleDense(2)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.Dense1(x)\n",
    "        return self.Dense2(x)\n",
    "    \n",
    "# Create an instance of the model\n",
    "my_model = Sequential(name=\"the_model\")\n",
    "print(\"Model results: \", my_model(tf.constant([[2.0, 2.0, 2.0]])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save tf.Module as `checkpoint`and as a `SavedModel`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Checkpoints"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoints are just the weights, that is, the values of all variables inside the module and its submodules. They consist of two files, the data itself and the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my_checkpoint'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"my_checkpoint\"\n",
    "checkpoint = tf.train.Checkpoint(my_model)\n",
    "checkpoint.write(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_checkpoint.data-00000-of-00001  my_checkpoint.index\n"
     ]
    }
   ],
   "source": [
    "!ls my_checkpoint*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dense1/b/.ATTRIBUTES/VARIABLE_VALUE', [3]),\n",
       " ('Dense1/w/.ATTRIBUTES/VARIABLE_VALUE', [3, 3]),\n",
       " ('Dense2/b/.ATTRIBUTES/VARIABLE_VALUE', [2]),\n",
       " ('Dense2/w/.ATTRIBUTES/VARIABLE_VALUE', [3, 2]),\n",
       " ('_CHECKPOINTABLE_OBJECT_GRAPH', [])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.list_variables(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[2.6006083, 0.7657103]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restoring weights from a checkpoint\n",
    "new_model = Sequential()\n",
    "new_checkpoint = tf.train.Checkpoint(new_model)\n",
    "new_checkpoint.restore(\"my_checkpoint\")\n",
    "\n",
    "new_model(tf.constant([[2.0, 2.0, 2.0]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow can run models without the original Python objects, that is, without the original Python code. This can be done with graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequentialModule(tf.Module):\n",
    "  def __init__(self, name=None):\n",
    "    super().__init__(name=name)\n",
    "\n",
    "    self.dense_1 = Dense(3, 3)\n",
    "    self.dense_2 = Dense(3, 2)\n",
    "\n",
    "  @tf.function\n",
    "  def __call__(self, x):\n",
    "    x = self.dense_1(x)\n",
    "    return self.dense_2(x)\n",
    "\n",
    "# You have made a model with a graph!\n",
    "my_model = MySequentialModule(name=\"the_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0. 0.]], shape=(1, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0. 0.]\n",
      " [0. 0.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(my_model([[2.0, 2.0, 2.0]]))\n",
    "print(my_model([[2.0, 2.0, 2.0], [2.0, 2.0, 2.0]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the graph with TensorBoard summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1.9432374 0.       ]], shape=(1, 2), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 10:04:18.369312: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2023-04-08 10:04:18.369333: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n"
     ]
    }
   ],
   "source": [
    "# Setting up logging\n",
    "stamp = datetime.now().strftime(\"%Y%m%d=%H%M%S\")\n",
    "logdir = \"logs/func/%s\" %stamp\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "# Create a new model to get a fresh trace\n",
    "# Else the summary will not see the graph\n",
    "new_model = Sequential()\n",
    "\n",
    "# Bracket the function call with tf.summary.trace_on()\n",
    "# and tf.summary.trace_export()\n",
    "tf.summary.trace_on(graph=True)\n",
    "tf.profiler.experimental.start(logdir)\n",
    "# Call only one tf.function while tracing\n",
    "z = print(new_model(tf.constant([[2.0, 2.0, 2.0]])))\n",
    "with writer.as_default():\n",
    "    tf.summary.trace_export(\n",
    "        \"myfunctrace\", step=0, profiler_outdir=logdir\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-94bb265a0711e287\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-94bb265a0711e287\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/func"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SavedModel` contains both a collection of functions and a collection of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: the_saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(my_model, \"the_saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 24\n",
      "drwxr-xr-x 2 ssk ssk  4096 Apr  8 10:04 \u001b[0m\u001b[01;34massets\u001b[0m/\n",
      "-rw-rw-r-- 1 ssk ssk 14296 Apr  8 10:04 saved_model.pb\n",
      "drwxr-xr-x 2 ssk ssk  4096 Apr  8 10:04 \u001b[01;34mvariables\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls -l the_saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\n",
      "-rw-rw-r-- 1 ssk ssk 490 Apr  8 10:04 variables.data-00000-of-00001\n",
      "-rw-rw-r-- 1 ssk ssk 356 Apr  8 10:04 variables.index\n"
     ]
    }
   ],
   "source": [
    "ls -l the_saved_model/variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models and layers can be loaded using these without making an instance of the class that created it. This is useeful in situations where we do not have a Python interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.saved_model.load(\"the_saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(new_model, Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
